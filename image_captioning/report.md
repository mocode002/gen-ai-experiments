# Image Captioning avec Attention (ResNet + LSTM) üñºÔ∏è

## 1. Introduction
Ce projet impl√©mente un syst√®me de **l√©gendage automatique d'images** (Image Captioning). L'objectif est de traduire le contenu visuel d'une image en une description textuelle naturelle.

Pour cela, nous avons con√ßu une architecture encodeur-d√©codeur hybride int√©grant un **m√©canisme d'attention (Attention Mechanism)**, permettant au mod√®le de se concentrer sur des zones sp√©cifiques de l'image lors de la g√©n√©ration de chaque mot.

## 2. Dataset : Flickr30k
Le dataset contient 30 000 images, chacune associ√©e √† plusieurs descriptions.
* **Traitement Image** : Redimensionnement (224x224), normalisation et transformation en tenseurs.
* **Traitement Texte** : Tokenisation, cr√©ation de vocabulaire, et utilisation d'embeddings pr√©-entra√Æn√©s.

## 3. Architecture Technique

### Encodeur : ResNet50 (Transfer Learning)
Nous utilisons un **ResNet50 pr√©-entra√Æn√©** dont nous avons retir√© les derni√®res couches fully connected.
* Contrairement aux approches classiques qui utilisent un vecteur global, nous extrayons les **features map spatiales** de la derni√®re couche de convolution.
* Les poids du ResNet sont gel√©s (frozen) pour conserver les caract√©ristiques visuelles apprises sur ImageNet.

### M√©canisme d'Attention (Custom Implementation)
Nous avons impl√©ment√© manuellement un module d'attention (type Bahdanau/Soft Attention).
* Il calcule des **scores d'attention** entre l'√©tat cach√© actuel du LSTM et les diff√©rentes zones de l'image (features du CNN).
* Cela produit un **vecteur de contexte** dynamique qui change √† chaque pas de temps de la g√©n√©ration du texte.

### D√©codeur : LSTM avec Attention
Un LSTM personnalis√© qui prend en entr√©e :
1.  Le mot pr√©c√©dent (via Embedding).
2.  L'√©tat cach√© pr√©c√©dent.
3.  Le vecteur de contexte (issu de l'attention).

## 4. Strat√©gie d'Entra√Ænement
* **Loss** : CrossEntropyLoss.
* **Scheduler** : Utilisation de `StepLR` pour r√©duire le learning rate progressivement et affiner la convergence.
* **Embeddings** : Initialisation avec les poids de Word2Vec pour acc√©l√©rer l'apprentissage s√©mantique.


## 5. R√©sultats et Exemples
Le mod√®le est capable d'aligner les mots g√©n√©r√©s avec les zones visuelles pertinentes.

**Exemple 1 :**

![red car](imgs/0.png)

**Exemple 2 :**

![mic](imgs/1.png)

## 6. Conclusion
L'ajout du m√©canisme d'attention am√©liore significativement la pertinence des l√©gendes par rapport √† une approche simple CNN-RNN. Ce TP a permis de ma√Ætriser l'impl√©mentation de couches personnalis√©es dans PyTorch et la gestion complexe des dimensions de tenseurs dans les mod√®les multimodaux.